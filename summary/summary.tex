\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\setlength\parindent{0pt}

\title{Heuristic Summary}
\author{Massimo Perego}
\date{}

\begin{document}
	
	\maketitle
	
	\tableofcontents
	
	\newpage
	
	\addcontentsline{toc}{section}{\protect\numberline{}TL;DR: Problems}
	\section*{TL;DR: Problems}
	
	\paragraph{Combinatorial Optimization:} A problem is a CO problem if we need to optimize an objective function and the solution is a subset of a finite ground set, from which the search space is defined.\\
	
	\paragraph{Knapsack Problem KP:} From a set of object, select the subset with maximal value that stays within a weight constraint.\\
	
	\paragraph{Maximum Diversity Problem MDP:} Inside a metric space, select the $k$ points with the maximum pairwise distance.\\
	
	\paragraph{Bin Packing Problem BPP:} Put a set of objects into the minimum number of containers, given the capacity of each container.\\
	
	\paragraph{Parallel Machine Scheduling Problem PMSP:} Divide a set of tasks, each with its own length, among a set of machines, minimizing the maximum length of a singular machine.\\
	
	\paragraph{Max-Sat:} Given a CNF, assign truth values to the logical variables in a way that satisfies the maximum weight subset of its logical clauses.\\
	
	\paragraph{Set Covering Problem SCP:} Given a binary matrix, select a subset of column of minimum cost covering all rows at least once.\\
	
	\paragraph{Set Packing Problem:} Given a binary matrix, select the subset of non-conflicting columns with maximum value (each row covered by at most one column).\\
	
	\paragraph{Set Partitioning Problem SPP:} Given a binary matrix, select a subset of non-conflicting column of minimum cost, covering each row (exactly one column for each row).\\
	
	\paragraph{Vertex Cover Problem VCP:} Given an undirected graph, select the subset of vertices of minimum weight/cardinality such that each edge is incident to at least one vertex in the solution.\\
	
	\paragraph{Maximum Clique Problem:} Given an undirected graph, find the subset of pairwise adjacent vertices of maximum weight (heaviest clique possible). \\
	
	\paragraph{Maximum Independent Set Problem:} Given an undirected graph, find the subset of pairwise non-adjacent vertices of maximum weight (heaviest set of independent vertices).\\
	
	\paragraph{Traveling Salesman Problem TSP:} Given a directed graph, find the Hamiltonian circuit of minimum weight, i.e., a circuit such that it visits each node exactly once (weight on the arcs, obv).\\
	
	\paragraph{Capacitated Minimum Spanning Tree Problem CMSTP:} Starting from a root, find the minimum spanning tree such that each branch respects a capacity (number/sum of weight of the arcs).\\
	
	\paragraph{Vehicle Routing Problem VRP:} Given a directed graph, with a starting node, select the set of circuits such that each node is visited exactly once and each circuit respects the capacity.\\
	
	
	\addcontentsline{toc}{section}{\protect\numberline{}Algorithm Analysis}
	\section*{Algorithm Analysis}
	
	\paragraph{Approximation:} To determine how "good" an algorithm is, we can look at how close its solution ($f_A (i)$) is to the optimal one ($f^\ast (i)$): 
	\begin{itemize}
		\item \textbf{Absolute difference $\tilde \delta_A(I)$:} the simple difference between solution found and optimal solution
		$$ \tilde{\delta}_A (I) = f_A (I) - f^\ast (I) $$
		\item \textbf{Relative difference $\delta_A (I)$:} it's the ratio between the absolute difference and the optimum (often as a percentage)
		$$ \delta_A(I) = \frac{f_A (I) - f^\ast (I)}{f^\ast (I)} $$
		\item \textbf{Approximation ratio $\rho_A (I)$:} The ratio solution found and optimal solution
		$$ \rho_A (I) = \frac{f_A (I)}{f^\ast (I)} $$
	\end{itemize}
	These are all for minimization problems, everything is switched for maximization (keep stuff always positive/greater than $1$).\\
	
	\paragraph{Worst case analysis:} A compact measure, independent of the instance, is the worst case; the approximation can be: 
	\begin{itemize}
		\item \textbf{Absolute:} the result will never be worse than the optimum by more than a fixed amount;
		\item\textbf{Relative:} the ratio of the approximate result and optimal one will never exceed a certain constant $\alpha$.\\
	\end{itemize}
	
	\paragraph{Beyond the worst case:} Using only the worst case can be \textit{rough}, some alternative approaches are: 
	\begin{itemize}
		\item \textbf{Average-case:} assume a probability distribution on the instances and evaluate the expected value of the approximation factor;
		\item \textbf{Randomization:} the operations of the algorithm depend on some random values, the solution becomes a random variable that can be investigated;
		\item \textbf{Parametrization:} prove an approximation guarantee that depends on other parameters of the instances besides the size $n$; we can add a parameter $k$ and the time can be expressed as $T(n,k)$, making it dependent on both; the problem could be polynomial in $n$ but exponential in $k$; $k$ could be part of the input or the solution (in which case we'll know it only \textit{a posteriori}, but an estimate could be available); 
		\item \textbf{Kernelization:} transform all instances of the problem into simpler ones, instead of instances of another problem; it becomes a simpler problem to solve, allowing it to be solved faster (either exactly or heuristically) or to prove that there exists an optimal solution  and maybe know which elements are certainly in or out of said solution.\\
	\end{itemize}
	
	\paragraph{Run Time Distribution Diagram RTD:} It shows the probability that the execution time is below a certain time $t$ (axis: runtime-$P$ of solving). To draw it: how many of the instances are solved in that amount of time or less?\\
	
	\paragraph{Scaling Diagram:} Describes the dependence of the time on the size (axis: instance size-execution time). A straight line with a logarithmic scale for the time only shows that the algorithm is exponential, if both axis are logarithmic it shows that the algorithm is polynomial. To find the coefficient: choose two points and 
	$$ \left(\frac{s_1}{s_2}\right)^\alpha \approx \frac{T_1}{T_2}$$
	find $\alpha$, with $s_1, s_2$ and $T_1, T_2$ instance sizes and times respectively.\\
	
	\paragraph{Solution Quality Diagram SQD:} It plots the probability that the relative difference $\delta$ is smaller than a value $\alpha$, for each possible value of $\alpha$ (axis: relative solution quality-cumulative frequency, i.e., how many times do we get that solution quality or better). To draw it: sort the relative differences by non-decreasing values and determine how many of the instances are under each value.\\
	
	\paragraph{Boxplot diagram:} Show median ($n/2$th element), surrounded by the box formed by the lower and upper quartiles ($n/4$th element and $3n/4$th element, respectively). The whiskers go out to the end of the range in both directions.\\
	
	\paragraph{Dominance:} The dominance can be: 
	\begin{itemize}
		\item \textbf{Strict:} a boxplot is fully below the other;
		\item \textbf{Probabilistic:} each quartile is not above the corresponding one of the other algorithm.\\
	\end{itemize}
	
	\paragraph{Wilcoxon's Test:} It's a test, focused on effectiveness, used to determine if the empirical difference among two algorithms is significant. Steps:
	\begin{enumerate}
		\item Compute the difference of the algorithms results, instance by instance
		\item Sort them by increasing absolute values and assign a rank (number) to each one
		\item Give a sign to each rank, positive if the difference was positive, negative otherwise
		\item Sum all positive ranks ($W^+$), as well as the negative ($W^-$)
		\item Calculate the probability that $|W^+ - W^-|$ is equal or larger than the observed value (usually not required during exams)
	\end{enumerate}
	If the probability is low enough the difference is significant and if $W^+ > W^-$ then the first algorithm is better than the second, or vice versa.\\
	
	\addcontentsline{toc}{section}{\protect\numberline{}Constructive Heuristics}
	\section*{Constructive Heuristics}
	
	\paragraph{Construction Graph:} Every construction heuristic $A$ defines a construction graph, in which the nodes are all the possible subsets $x \subseteq B$ acceptable for $A$, and the arcs connect all solution pairs such as $(x, x \cup \{i\})$, with $x, x \cup \{i\} \in \mathcal{F}_A$, $i \in B \setminus x$ (same solution, cardinality of one more). The graph is directed and acyclic by definition. Every possible execution of the algorithm is a maximal path (ends in a node with no more outgoing arcs) starting from $\emptyset$.\\
	
	\paragraph{Pure and Adaptive:} A constructive algorithm is 
	\begin{itemize}
		\item \textbf{Pure:} if the selection criterion $\varphi_A$ depends only on the new element $i$;
		\item \textbf{Adaptive:} if $\varphi_A$ depends both on $i$ and the current solution.\\
	\end{itemize}
	
	\paragraph{Traveling Salesman Problem TSP:} Types of Heuristic: 
	\begin{itemize}
		\item \textbf{Nearest Neighbor:} from the last visited node to the nearest unvisited node;
		\item \textbf{Cheapest Insertion:} removes an arc and adds two, including a new node, such that the total change is minimum;
		\item \textbf{Nearest Insertion:} look for the node closest to the circuit (minimum distance from another node in the circuit) and find the best way to include it (which arc do I remove to include it? Use the one that minimizes total weight);
		\item \textbf{Farthest Insertion:} search for the node farthest from the circuit and connect it in the best way possible.\\
	\end{itemize}
	
	\paragraph{Greedoids and Matroids:} Assuming that the objective function is additive, and the solutions are bases (maximal subsets, can't add any more stuff) of the search space. A greedy algorithm is possible for a problem (ground set $B$ and search space $\mathcal{F} \subseteq 2^B$) which is a \textbf{greedoid}, i.e., for which the following hold: 
	\begin{itemize}
		\item \textbf{Trivial axiom:} $\emptyset \in \mathcal{F}$, the empty set is an acceptable solution;
		\item \textbf{Accessibility axiom:} if $x \in \mathcal{F}$ and $x \neq \emptyset$ then $\exists i \in x : \, x \setminus \{i\} \in \mathcal{F}$. Any acceptable subset can be built adding its element in a suitable order, i.e., there is at least one path that leads to every solution in the search space;
		\item \textbf{Exchange axiom:}  if $x, y \in \mathcal{F}$ with $|x| = |y| + 1$, then $\exists i \in x \setminus y$ such that $y \cup \{i\} \in \mathcal{F}$, any acceptable solution can be extended with a suitable element from a bigger solution.
	\end{itemize}
	Strengthening the accessibility axiom leads to a \textbf{matroid}: 
	\begin{itemize}
		\item \textbf{Heredity axiom:} if $x \in \mathcal{F}$ and $y \subset x$ then $y \in \mathcal{F}$. Any acceptable subset can be built by adding elements in any order.\\
	\end{itemize}
	
	\paragraph{Optimality of the greedy/constructive algorithm:} The constructive algorithm finds the optimal solution if $(B, \mathcal{F})$ is a matroid embedding. The optimality of the greedy algorithm can also be proven for a greedoid with strengthened exchange axiom: 
	\begin{itemize}
		\item \textbf{Strong exchange axiom:}
		$$ 
		\begin{cases}
			x \in \mathcal{F}, y \in B_{\mathcal{F}} & \text{ s.t. } x \subset y \\
			i \in B \setminus y & \text{ s.t. } x \cup \left\{i\right\} \in \mathcal{F}
		\end{cases}
		\implies \exists j \in y \setminus x: \, 
		\begin{cases}
			x \cup \left\{j\right\} \in \mathcal{F} \\
			y \cup \left\{i\right\} \setminus \left\{j\right\} \in \mathcal{F}
		\end{cases}
		$$
	\end{itemize}
	Given a base $y$ and a subset of the search space and base $x$, you can have an element $i$ in the base but not in $y$ that can be feasibly added to $x$. Then there is an element $j$ in $y$ but not $x$ that can be added to $x$ while replacing $j$ with $i$ in the base, all while remaining in the search space.\\
	
	\paragraph{Regret-based constructive heuristics:} What if something is good now but bad later? We want to measure the "bad later" with a regret function. Usually such a heuristic consists of:
	\begin{itemize}
		\item Partitioning the choices in classes;
		\item Compute, for each choice, the basic selection criteria;
		\item Compute, for each class, the regret, i.e., usually, the difference with the second-best choice or the average of all other choices;
		\item Choose the best choice for the class in which regret is maximum;
	\end{itemize}
	This works well when we know we'll have to pick from each class, and we fear being stuck with a much worse choice later.\\
	
	\paragraph{Roll-out heuristics:} Also known as single-step look-ahead constructive heuristics, at each step of the basic heuristic look ahead at the next step and compute the solution for each possibility. The complexity remains polynomial but much larger (it increases by the cardinality of the base set squared). It can be extended to multiple steps, worsening further the complexity.\\
	
	\paragraph{Destructive Heuristics:} Start with the full ground set and remove one element at a time, always remaining in the search space and while maximizing the selection criteria. Usually the solutions are much smaller than the ground set, so they take too long , but it might be useful to append a destructive heuristic to constructive solutions which might have redundant elements.\\
	
	\addcontentsline{toc}{section}{\protect\numberline{}Constructive Metaheuristics}
	\section*{Constructive Metaheuristics}
	
	\paragraph{Adaptive Research Technique ART:} Set a number of iterations $\ell$ for a basic constructive heuristic, at each iteration forbid elements inside the solution with probability $\pi$ for a number of iteration $L$. When wanting to include an element, check that the current iteration is distant enough from the last ban of said element, i.e., if $t > T_i + L$ where $t$ is the current iteration and $T$ is the vector containing the tabu attribute for each element.\\
	
	\paragraph{Greedy randomized Adaptive Search Procedure GRASP:} Also called semi-greedy, instead of always choosing the best at each step, sometimes make a random step. How can we determine which step? 
	\begin{itemize}
		\item \textbf{Uniform probability:} each possibility has the same probability;
		\item \textbf{HBSS:} sort the possibilities by non-increasing values of $\varphi$, assign a probability according to the position in the order;
		\item \textbf{Restricted Candidate List:} sort the possibilities, choose from a number of choices among the best. We can define the RCL through 
		\begin{itemize}
			\item \textbf{Cardinality:} take the $\mu$ best elements
			\item \textbf{Value:} include all the elements 
			\begin{itemize}
				\item for minimization problems, with value below:
				$$ \varphi_\mu = \varphi_{\min} + \mu(\varphi_{\max} - \varphi_{\min}) = (1 - \mu) \varphi_{\min} + \mu \varphi_{\max} $$
				\item for maximization problems, with value above:
				$$ \varphi_\mu = \varphi_{\max} - \mu (\varphi_{\max} - \varphi_{\min}) = (1 - \mu) \varphi_{\max} + \mu \varphi_{\min} $$
			\end{itemize}
		\end{itemize}
		We choose randomly among the \textit{elite}.\\
	\end{itemize}
	
	\paragraph{Ant System:} Similar to semi-greedy, but all choices are feasible and the probability of choosing an element is a function which depends on the selection criteria ($\varphi$, which is turned into visibility $\eta$) and some auxiliary information (trail $\tau$), updated after each iteration. To update we have the oblivion parameter $\rho$ and the conversion coefficient $Q$: 
	$$ 
	\tau_i = \begin{cases}
		(1 - \rho) \tau_i & \text{ for } i \notin x \\
		(1 - \rho) \tau_i + \rho \cdot Q \cdot f(x) & \text{ for } i \in x \\
	\end{cases}
	$$
	where $f(x)$ is the value of the final solution. We multiply all trails by $(1-\rho)$ and then add $\rho Q f(x)$ to the elements in the current solution, since they're "promising".\\

	\addcontentsline{toc}{section}{\protect\numberline{}Exchange Heuristics}
	\section*{Exchange Heuristics}
	
	\paragraph{Neighborhood:} $N: X \rightarrow 2^X$, a neighborhood is a function which associates each feasible solution to a subset of feasible solutions. We can define a neighborhood based on: 
	\begin{itemize}
		\item \textbf{Distance:} how distant a solution is from another, all the solutions within a certain distance form a neighborhood. An example of distance is the Hamming distance: if we represent the solution as the incidence vector of its elements, the Hamming distance is the number of elements in which the solutions differ, e.g., $N_{\mathcal{H}_1}$ is the neighborhood of solutions one element away from each other; 
		\item \textbf{Operations:} how many operations $\mathcal{O}$ are needed to get from a solution to another, e.g., $N_{\mathcal{S}_1}$ is the neighborhood with an element swapped. \\
	\end{itemize}
	
	\paragraph{Steepest Descent:} Starting from a solution, move to the best solution in the neighborhood and repeat until there are only worsening moves. The best solution is always the last one and is a local optima. Possible strategies: 
	\begin{itemize}
		\item \textbf{Global best:} among all neighboring solutions take the most improving;
		\item \textbf{First-best:} choose an order for the solutions in the neighborhood and select the first improving one found.\\
	\end{itemize}
	
	\paragraph{Landscape:} It's the triplet $(X,N,f)$, where $X$ is the search space, $N$ is the neighborhood function and $f$ is the objective function. It is the search graph with node weights given by the objective. The effectiveness of Steepest Descent depends on the landscape, the smoother it is the better the results.\\
	
	\paragraph{Very Large Scale Neighborhood (VLSN):} Larger neighborhoods (generally) yield larger attraction basins, making Steepest Descent more effective, but they take longer to explore. With Very Large Scale Neighborhoods (exponential/high polynomial in $|B|$) we need to limit computational time: if the objective can be optimized without an exhaustive search we can explore the neighborhood heuristically. We want to parameterize the neighborhood, define a composite move as a set of elementary moves (compatible and commutable) and increase or decrease the number of operations when necessary/sufficient to improve the solution. Finding the optimal solution in such neighborhoods requires solving an auxiliary problem, typically on a matrix or graph.\\
	
	\paragraph{Order-first Split-second:} It's a method used for solving partition problems:
	\begin{itemize}
		\item Build a starting permutation of the elements to be partitioned
		\item Partition in an optimum way, under the additional constraint that elements of the same component be consecutive in the starting permutation (keep the ordering)
	\end{itemize}
	We can exploit an \textbf{auxiliary graph}: 
	\begin{itemize}
		\item each node corresponds to an element, plus a fictitious node $0$;
		\item starting from each node, there's an arc to the next if adding that component is feasible for the solution (consider all the elements from the node in which we started, do this starting from each node).\\
	\end{itemize}
	
	\paragraph{Variable Depth Search VDS:} A composite move is a sequence of elementary moves. From each solution in the basic neighborhood, make a sequence of moves optimizing each elementary step, while allowing worsening moves and forbidding backwards moves. Terminate when the solution becomes worse than the starting one or all moves are forbidden, return the best solution found along the way. Kinda like a roll-out for exchange heuristics, try all moves (without getting \textit{too bad}, it's bounded in the original solution) and find out what works best.\\
	
	\paragraph{Destroy and Repair:} Also called iterated greedy methods, when the \textit{right} number of exchanges is unknown it's a possible idea to:
	\begin{itemize}
		\item delete from the solution a certain number of elements $k$;
		\item complete it with a constructive (repair) heuristic.\\
	\end{itemize}
	
	\addcontentsline{toc}{section}{\protect\numberline{}Exchange Metaheuristics}
	\section*{Exchange Metaheuristics}
	
	\paragraph{Iterated Local Search ILS:} At each iteration, it perturbates the last accepted solution to create a new starting point, finds the local optima from there and then it decides whether to accept it or not. The perturbation procedure (ideally) allows to move out of the attraction basin of a local optima (not too strong or it's a random restart, not too weak or it risks remaining in the same basin) and the acceptance procedure evaluates whether the result found is a promising starting point for the following iterations (accepting only improving solution favors intensification, accepting any solution favors diversification, has to be tuned). \\
	
	\paragraph{Variable Neighborhood Search VNS:} Finds the local optima for a certain neighborhood using Steepest Descent, then there's a shaking procedure to obtain a new starting solution, randomly extracted from the current neighborhood considered, repeat for a number $\ell$ of iteration. There's a hierarchy of neighborhoods and, after each iteration, if a better solution was found a smaller neighborhood is selected (intensification), a larger one is used otherwise (diversification).\\
	
	\paragraph{Variable Neighborhood Descent VND:} If a solution is the local optima for a certain neighborhood, then changing the neighborhood might lead to a better solution. It uses a family of neighborhoods, explores each one until it finds the local optima, then goes to the next one until the solution is a local optima for all neighborhoods. The neighborhoods can be heterogeneous (topologically different, e.g., $N_{\mathcal{S}_1}$ and $N_{\mathcal{T}_1}$) or hierarchical ($N_1 \subset \dots \subset N_k$). The last solution found is always the best one.\\
	
	\paragraph{Dynamic Local Search DLS:} It keeps the neighborhood but modifies the objective function during the search to escape the local optima; useful when the objective function has many plateaus. The basic idea is to: 
	\begin{itemize}
		\item Define a penalty function $w: X \rightarrow \mathbb{N}$;
		\item Combine the penalty and objective functions into one auxiliary function $\tilde f$; it can be applied additively or multiplicatively to the values of the elements;
		\item Apply Steepest Descent, optimizing $\tilde f$;
		\item After each iteration update the penalty values based on the results, modifying the landscape of the search.\\
	\end{itemize}
	
	\paragraph{Simulated Annealing:} Start from a solution in a neighborhood, extract another solution at random, compute its value, accept it if better, if it's worse accept it with a certain probability dependent on the temperature, usually $e^{-\delta f / T}$, where $\delta f$ is the difference between current and new solution and $T$ is the temperature. The temperature is gradually reduced after each iteration, lowering the probability of accepting worsening solution as time goes on.\\
	
	\paragraph{Tabu Search:} It keeps the basic selection criteria of Steepest Descent, removes the termination condition (beware of cycling!) and imposes a tabu on already visited solutions. While exploring a neighborhood, at each step it selects the best feasible non-tabu solution. It is potentially inefficient: at step $t$ it needs to check that the solution is new (the evaluation must be efficient) and the number of solutions grows indefinitely, along with the memory occupation. Forbidding solutions can also lead to disconnection of the search graph and/or slow down the exit from attraction basins. Solutions to these problems: forbid "attributes" instead of solutions or/and give a duration to the prohibition (tabu tenure).\\
	
	\addcontentsline{toc}{section}{\protect\numberline{}Recombination Algorithms}
	\section*{Recombination Algorithms}
	
	\paragraph{Scatter Search:} It generates a starting population of solutions and improves all of them with an exchange procedure, then it builds a reference set $R = B \cup D$ where $B$ includes the best solutions and $D$ the farthest solution from $B$ (by some definition of distance). For each pair of solutions $(x,y) \in B \times (B \cup D)$: 
	\begin{itemize}
		\item Recombine $x$ and $y$, generating $z$
		\item Improve $z$ with an exchange procedure, obtaining $z'$
		\item Check if $z'$ belongs to either $B$ or $D$
		\item Terminate when $R$ is unchanged
	\end{itemize}
	Recombining inside $(B \times B)$ intensifies the search, while recombinations inside $(B \times D)$ diversify.\\
	
	\paragraph{Recombination:} Usually the solutions $x$ and $y$ are manipulated as subsets; the recombination goes as follows: 
	\begin{enumerate}
		\item Start with $z = x \cap y$, they concur, so they \textit{must} be good elements (right?);
		\item Augment $z$ using elements from $x\setminus y$ or $y \setminus x$, using some criteria;
		\item If necessary, add external elements from $B \setminus (x \cap y)$;
		\item If necessary ($z$ is unfeasible), apply an auxiliary exchange heuristic (repair procedure).\\
	\end{enumerate}
	
	\paragraph{Path Relinking:} Given a neighborhood $N$ and an exchange heuristic based on it, collect in a reference set $R$ the best solutions generated by the auxiliary heuristic (often this is just a final intensification, that one is the normal heuristic) and for each pair of solutions $x,y \in R$
	\begin{itemize}
		\item Build a path from $x$ to $y$ inside the neighborhood, choosing at each step the solution closest to $y$;
		\item Find the best solution along the path (maybe improve it);
		\item If said solution it's good enough for the reference set, add it to $R$.\\
	\end{itemize}
	
	\paragraph{Encoding-based Algorithms:} Many recombination heuristics manipulate encodings of the solutions, rather than the solutions themselves, this aims to abstract and distinguish the method from the problem, while building an operator that can work with any problem that uses a certain family of encoding.\\
	
	\paragraph{Features of a Good Encoding:} The following properties should be satisfied by a good encoding (decreasing importance):
	\begin{enumerate}
		\item Each solution should have an encoding;
		\item Different solutions should have different encodings;
		\item Each encoding should correspond to a feasible solution;
		\item Each solution should correspond to the same number of encodings;
		\item The encoding and decoding operations should be efficient;
		\item Locality: small changes to the encoding should induce small changes to the solution.\\
	\end{enumerate}
	
	\paragraph{Usual encodings:} Some common encodings are:
	\begin{itemize}
		\item \textbf{Incidence vector:} A binary vector where each element corresponds to an item in the ground set and the value determines whether the object is in the solution or not; e.g., KP, if the value is 1 the element is in the knapsack;
		\item \textbf{Symbol strings:} When the ground set is divided into disjoint components and the solution must take one element from each component, we can define an alphabet for each component, with symbols corresponding to each element that can be part of that component in the solution; e.g., in the PMSP, we define an alphabet for each machine, containing a symbol for all possible tasks, whose inclusion in the solution means that said task is assigned to that specific machine;
		\item \textbf{Permutations:} If the solution can be expressed as permutation of a set, this can serve as an encoding; e.g., in the TSP, the solution is a permutation of nodes.\\
	\end{itemize}
	
	\paragraph{Genetic Algorithm:} The most famous encoding algorithm, it builds and encodes a population and repeatedly applies: 
	\begin{itemize}
		\item \textbf{Selection:} generate a new population starting from the current one, extracting elements with probability proportional to the fitness (the selection can either be proportional, simple probability related to the fitness value, rank, probability related to the "position in the fitness line", or tournament selection, extracting a number of subsets and choosing the best individual from each subset);
		\item \textbf{Crossover:} combines 2 or more individuals to generate other, usually by splitting and swapping parts of the encoding;
		\item \textbf{Mutation:} modifies an individual to generate a similar one, the modification usually depends on the encoding, e.g., binary vector: flip some bits, Symbol strings: substitute some symbols at random, Permutations: swap elements, in some way. \\
	\end{itemize}
	
	\paragraph{Feasibility within encodings:} Sometimes, crossover and mutation can generate encodings of legal but unfeasible solutions, this can lead to inefficiency, ineffectiveness and design problems. Approaches to face this problem can be: 
	\begin{itemize}
		\item \textbf{Special encodings and operators:} to avoid/limit unfeasibility; e.g., only encode feasible solutions (such as with symbol strings for partitioning problems, can't get unfeasible with that) or define crossover/mutation operators that maintain feasibility, such as ones which simulate moves on the solutions; we're kinda giving up on abstraction though and going back to heuristics based on neighborhoods;
		\item \textbf{Repair procedures:} turn unfeasibility into feasibility; refine the decoder function to repair unfeasible solutions; this allows a bias in favor of feasible encodings and in favor of solutions which are more easily obtained by the repair procedure;
		\item \textbf{Penalty functions:} allow unfeasibility but discourage it; add a measure of unfeasibility (which has to be defined) to the fitness function, penalizing unfeasible solutions (which often have a better value of the objective function); it's better to use the smallest effective penalty to allow reaching "hidden" feasible solutions while not allowing too many unfeasible solutions to be found, it has to be tuned.\\
	\end{itemize}
	
\end{document}